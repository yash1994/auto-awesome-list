# [Intel](https://github.com/intel)

Intel currently holds 693 public repositories out of which 17 are related to data science and machine learning.

 ### Last Updated On:09-07-20

## Newly Added

| Name | Description | Language | Stars | License |
| ---- | ----------- | :--------: | :-----: | :-------: |
| [inference-engine-node](https://github.com/intel/inference-engine-node) | Bringing the hardware accelerated deep learning inference to Node.js and Electron.js apps. | JavaScript | 19 | Apache License 2.0 |
| [riggingtools](https://github.com/intel/riggingtools) | Collection of tools bridging the gap between 3D skeletal tracking and animation | C++ | 6 | MIT License |
| [lp-inference-kit](https://github.com/intel/lp-inference-kit) | Intel Low Precision Inference Tool, targeting to provide a unified low precision inference interface cross different deep learning frameworks, and support auto-tune with specified accuracy criterion to find out best quantized model. | Python | 5 | Apache License 2.0 |
| [cppnnml](https://github.com/intel/cppnnml) | The C++ Neural Network and Machine Learning project is intended to provide a C++ template library for neural nets and machine learning algorithms within embedded systems | C++ | 4 | MIT License |

## Highly Rated

| Name | Description | Language | Stars | License |
| ---- | ----------- | :--------: | :-----: | :-------: |
 | [caffe](https://github.com/intel/caffe) | This fork of BVLC/Caffe is dedicated to improving performance of this deep learning framework when running on CPU, in particular Intel® Xeon processors. | C++ | 786 | Other |
| [clDNN](https://github.com/intel/clDNN) | Compute Library for Deep Neural Networks (clDNN) | C++ | 524 | N/A |
| [compute-runtime](https://github.com/intel/compute-runtime) | Intel® Graphics Compute Runtime for oneAPI Level Zero and OpenCL™ Driver | C++ | 499 | MIT License |
| [idlf](https://github.com/intel/idlf) | Intel® Deep Learning Framework | C++ | 320 | Other |
| [ad-rss-lib](https://github.com/intel/ad-rss-lib) | Library implementing the Responsibility Sensitive Safety model (RSS) for Autonomous Vehicles | C++ | 122 | Other |
| [webml-polyfill](https://github.com/intel/webml-polyfill) | A polyfill for Web Neural Network (WebNN) API | Python | 110 | Apache License 2.0 |
| [MLSL](https://github.com/intel/MLSL) | Intel(R) Machine Learning Scaling Library is a library providing an efficient implementation of communication patterns used in deep learning. | C++ | 108 | Other |
| [dffml](https://github.com/intel/dffml) | The easiest way to use Machine Learning | Python | 82 | MIT License |
| [compute-samples](https://github.com/intel/compute-samples) |  Intel® GPU Compute Samples | C++ | 51 | MIT License |
| [torch](https://github.com/intel/torch) | Torch is a scientific computing framework with wide support for machine learning algorithms. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation. | CMake | 37 | BSD 3-Clause "New" or "Revised" License |
| [neuro-vectorizer](https://github.com/intel/neuro-vectorizer) | NeuroVectorizer is a framework that uses deep reinforcement learning (RL) to predict optimal vectorization compiler pragmas for for loops in C and C++ codes.  | C | 37 | BSD 3-Clause "New" or "Revised" License |
| [spark-mpi-adapter](https://github.com/intel/spark-mpi-adapter) | MPI Adapter for Apache Spark | C++ | 8 | BSD 3-Clause "New" or "Revised" License |
| [stacks](https://github.com/intel/stacks) | The System Stacks for Linux* OS are a collection of production ready docker images for Deep Learning, Media and Storage optimized for 2nd generation Intel® Xeon® Scalable Processors. | Shell | 7 | Apache License 2.0 |
